{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5hxxkdAQJg"
   },
   "source": [
    "<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Word2vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCED1hh-Ioyf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PUbfVnzIIoMj"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOa4JPSCJ29"
   },
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RIO7b8GjAC17"
   },
   "outputs": [],
   "source": [
    "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WqdaTmO8P1r"
   },
   "source": [
    "Documento 1 --> que dia es hoy \\\n",
    "Documento 2 --> martes el dia de hoy es martes \\\n",
    "Documento 3 --> martes muchas gracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVHxBRNzCMOS"
   },
   "source": [
    "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
    "- Cada documento transformarlo en una lista de términos\n",
    "- Armar un vector de términos no repetidos de todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_components_from_corpus(corpus):\n",
    "    splitted_corpus = np.char.split(corpus, ',')\n",
    "    documents_in_corpus = [words.split(' ') for document in splitted_corpus\n",
    "                              for words in document]\n",
    "    vocabulary = set([word for document in documents_in_corpus\n",
    "                              for word in document])\n",
    "    vocabulary = list(vocabulary)\n",
    "    return (sorted(vocabulary), splitted_corpus, documents_in_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3ZqTOZzDI7uv"
   },
   "outputs": [],
   "source": [
    "vocabulary, _, _ = get_vocabulary_components_from_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUhH983FI7It"
   },
   "source": [
    "### 2- OneHot encoding\n",
    "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Os0AAQo6I6Z1"
   },
   "outputs": [],
   "source": [
    "def get_one_hot_encoder(corpus, add_column_names=True):\n",
    "    vocabulary, splitted_corpus, documents_in_corpus = get_vocabulary_components_from_corpus(corpus)\n",
    "    ohes = []\n",
    "    if add_column_names:\n",
    "        ohes.append(np.array(vocabulary, dtype=object))\n",
    "    for document in documents_in_corpus:\n",
    "        indexes = np.isin(vocabulary, document)\n",
    "        ohe = np.zeros([len(vocabulary)])\n",
    "        ohe[indexes] = 1\n",
    "        ohes.append(np.array(ohe, dtype=int))\n",
    "    return np.array(ohes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = get_one_hot_encoder(corpus, add_column_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
      " [0 1 0 1 0 1 0 0 1]\n",
      " [1 1 1 1 0 1 1 0 0]\n",
      " [0 0 0 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIyWGmCpJVQL"
   },
   "source": [
    "### 3- Vectores de frecuencia\n",
    "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_vectorizer(corpus, add_column_names=True):\n",
    "    vocabulary, splitted_corpus, documents_in_corpus = get_vocabulary_components_from_corpus(corpus)\n",
    "    ohes = []\n",
    "    if add_column_names:\n",
    "        ohes.append(np.array(vocabulary, dtype=object))\n",
    "    for document in documents_in_corpus:\n",
    "        indexes = np.isin(vocabulary, document)\n",
    "        indexes = np.where(indexes)\n",
    "        ohe = np.zeros([len(vocabulary)])\n",
    "        for index in indexes[0]:\n",
    "            word = vocabulary[index]\n",
    "            count = 0\n",
    "            for w in document:\n",
    "                if w == word:\n",
    "                    count += 1\n",
    "            ohe[index] = count\n",
    "        ohes.append(np.array(ohe, dtype=int))\n",
    "    return np.array(ohes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = get_count_vectorizer(corpus, add_column_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
      " [0 1 0 1 0 1 0 0 1]\n",
      " [1 1 1 1 0 1 2 0 0]\n",
      " [0 0 0 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Ot8HvWJcBu"
   },
   "source": [
    "### 4- TF-IDF\n",
    "Data una lista de textos, devolver una matriz con la representacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "waG_oWtpJjRw"
   },
   "outputs": [],
   "source": [
    "def TF_IDF(corpus, add_column_names=True):\n",
    "    vocabulary, splitted_corpus, _ = get_vocabulary_components_from_corpus(corpus)\n",
    "    vocabulary = np.array(vocabulary, dtype=object)\n",
    "    \n",
    "    tf = get_count_vectorizer(corpus, add_column_names=False) \n",
    "    \n",
    "    idf = get_one_hot_encoder(corpus, add_column_names=False)    \n",
    "    num = len(splitted_corpus)\n",
    "    den = np.sum(idf, axis=0)\n",
    "    idf = np.log10(np.divide(num, den, where=den!=0))\n",
    "    \n",
    "    tf_idf = tf * idf\n",
    "    \n",
    "    if add_column_names:\n",
    "        tf_idf = np.concatenate(([vocabulary], tf_idf), axis=0)\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TF_IDF(corpus, add_column_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
      " [0.0 0.17609125905568124 0.0 0.17609125905568124 0.0 0.17609125905568124\n",
      "  0.0 0.0 0.47712125471966244]\n",
      " [0.47712125471966244 0.17609125905568124 0.47712125471966244\n",
      "  0.17609125905568124 0.0 0.17609125905568124 0.3521825181113625 0.0 0.0]\n",
      " [0.0 0.0 0.0 0.0 0.47712125471966244 0.0 0.17609125905568124\n",
      "  0.47712125471966244 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMcsfndWJjm_"
   },
   "source": [
    "### 5 - Comparación de documentos\n",
    "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CZdiop6IJpZN"
   },
   "outputs": [],
   "source": [
    "def order_by_cosine_similarity(corpus, index, delete_item=True, use_tfidf=True):\n",
    "    splitted_corpus = np.char.split(corpus, ',')\n",
    "    if index < len(splitted_corpus):\n",
    "        args = (corpus, False)\n",
    "        elements = TF_IDF(*args) if use_tfidf else get_one_hot_encoder(*args)\n",
    "        element = elements[index]\n",
    "        scores = []\n",
    "        for document in elements:\n",
    "            cos_sim = cosine_similarity(document, element)\n",
    "            scores.append(cos_sim)\n",
    "        indexes = list(np.argsort(scores)[::-1])\n",
    "        if delete_item:\n",
    "            indexes.remove(index)\n",
    "        return splitted_corpus[indexes]\n",
    "    else:\n",
    "        raise IndexError('Index out of range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencias\n",
    "- **delete_item**: indica si hay que eliminar de las respuestas ordenadas el item correspondiente al índice proporcionado para calcular la similaridad coseno.\n",
    "- **use_tfidf**: si su valor es True utiliza el algoritmo TF IDF, en caso contrario utiliza el algoritmo One Hot Encoder para codificar los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que dia es hoy\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(corpus[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered = order_by_cosine_similarity(corpus, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['martes el dia de hoy es martes']) list(['martes muchas gracias'])]\n"
     ]
    }
   ],
   "source": [
    "print(ordered)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5fRYTpympAwJSVbric6dW",
   "collapsed_sections": [],
   "name": "1a - word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
